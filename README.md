## Tensorflow å®ç°YOLO V3æ£€æµ‹å®‰å…¨å¸½ä½©æˆ´

**Xu Jing**

æœ€è¿‘å‡ å¹´æ·±åº¦å­¦ä¹ çš„å‘å±•è®©å¾ˆå¤šè®¡ç®—æœºè§†è§‰ä»»åŠ¡è½åœ°æˆä¸ºå¯èƒ½ï¼Œè¿™äº›ä»»åŠ¡æ¸—é€åˆ°äº†å„è¡Œå„ä¸šï¼Œæ¯”å¦‚å·¥ä¸šå®‰å…¨ï¼ŒåŒ…å«çš„ä»»åŠ¡å¦‚å®‰å…¨å¸½ä½©æˆ´æ£€æµ‹ã€é«˜ç©ºå ç‰©æ£€æµ‹ã€å¼‚å¸¸äº‹æ•…æ£€æµ‹ï¼ˆè¡Œäººè·Œå€’ä¸èµ·ç­‰ï¼‰ï¼Œç«ç¾æ£€æµ‹ç­‰ç­‰ï¼Œæˆ‘ä»¬ä½¿ç”¨YOLO V3è®­ç»ƒäº†ä¸€ä¸ªå®‰å…¨å¸½ä½©æˆ´æ£€æµ‹çš„æ¨¡å‹ã€‚


### 1. ğŸ“£ æ•°æ®ä»‹ç»

ç¡®å®šäº†ä¸šåŠ¡åœºæ™¯ä¹‹åï¼Œéœ€è¦æ‰‹æœºå¤§é‡çš„æ•°æ®ï¼ˆä¹‹å‰å‚åŠ è¿‡ä¸€ä¸ªå®‰å…¨å¸½è¯†åˆ«æ£€æµ‹çš„æ¯”èµ›ï¼Œä½†æ˜¯æ•°æ®åœ¨æ¯”èµ›å¹³å°æ— æ³•ä¸‹è½½ä¸ºå·±ç”¨ï¼‰ï¼Œä¸€èˆ¬æ¥è¯´åŒ…å«ä¸¤å¤§æ¥æºï¼Œä¸€éƒ¨åˆ†æ˜¯ç½‘ç»œæ•°æ®ï¼Œå¯ä»¥é€šè¿‡ç™¾åº¦ã€Googleå›¾ç‰‡çˆ¬è™«æ‹¿åˆ°ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯ç”¨æˆ·åœºæ™¯çš„è§†é¢‘å½•åƒï¼Œåä¸€éƒ¨åˆ†ç›¸å¯¹æ¥è¯´æ•°æ®é‡æ›´å¤§ï¼Œä½†å‡ºäºå•†ä¸šå› ç´ å‡ ä¹ä¸ä¼šå¼€æ”¾ã€‚æœ¬æ–‡å¼€æºçš„å®‰å…¨å¸½æ£€æµ‹æ•°æ®é›†([SafetyHelmetWearing-Dataset, SHWD](https://github.com/njvisionpower/Safety-Helmet-Wearing-Dataset))ä¸»è¦é€šè¿‡çˆ¬è™«æ‹¿åˆ°ï¼Œæ€»å…±æœ‰7581å¼ å›¾åƒï¼ŒåŒ…å«9044ä¸ªä½©æˆ´å®‰å…¨å¸½çš„bounding boxï¼ˆæ­£ç±»ï¼‰ï¼Œä»¥åŠ111514ä¸ªæœªä½©æˆ´å®‰å…¨å¸½çš„bounding box(è´Ÿç±»)ï¼Œæ‰€æœ‰çš„å›¾åƒç”¨labelimgæ ‡æ³¨å‡ºç›®æ ‡åŒºåŸŸåŠç±»åˆ«ã€‚å…¶ä¸­æ¯ä¸ªbounding boxçš„æ ‡ç­¾ï¼šhatâ€è¡¨ç¤ºä½©æˆ´å®‰å…¨å¸½ï¼Œâ€œpersonâ€è¡¨ç¤ºæ™®é€šæœªä½©æˆ´çš„è¡Œäººå¤´éƒ¨åŒºåŸŸçš„bounding boxã€‚å¦å¤–æœ¬æ•°æ®é›†ä¸­personæ ‡ç­¾çš„æ•°æ®å¤§å¤šæ•°æ¥æºäº[SCUT-HEAD](https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release)æ•°æ®é›†ï¼Œç”¨äºåˆ¤æ–­æ˜¯æœªä½©æˆ´å®‰å…¨å¸½çš„äººã€‚å¤§è‡´è¯´ä¸€ä¸‹æ•°æ®é›†æ„é€ çš„è¿‡ç¨‹ï¼š

1.æ•°æ®çˆ¬å–

ç”¨çš„çˆ¬ç™¾åº¦å›¾ç‰‡å’ŒGoogleå›¾ç‰‡çš„æ–¹æ³•ï¼Œç™¾åº¦å›¾ç‰‡ç”¨è‡ªå·±å†™çš„è®¿é—®webé¡µé¢çš„æ–¹å¼ï¼Œé€šè¿‡ä¸åŒçš„å…³é”®è¯å¤šçº¿ç¨‹çˆ¬å–æ•°æ®ï¼Œå¦‚æœæ˜¯Googleå›¾çš„è¯æ¨èç”¨google-images-downloadï¼Œä½¿ç”¨æ–¹æ³•ä¸å¤šæè¿°ï¼Œä¹Ÿæ˜¯çˆ¬å–å¤šä¸ªä¸åŒçš„å…³é”®è¯ã€‚å…³é”®è¯æ˜¯ä¸ªå¾ˆæœ‰æ„æ€çš„é€‰é¡¹ï¼Œç›´æ¥ç”¨â€œå®‰å…¨å¸½â€è¿™æ ·çš„å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½çš„é€‰æ‹©ï¼Œæ›´å¤šçš„æ—¶å€™å¯ä»¥ç”¨â€œå»ºç­‘å·¥äººâ€ç­‰ä¹‹ç±»çš„è¯è¯­ï¼›è‹±æ–‡æ³¨æ„å®‰å…¨å¸½æ—¢å¯ä»¥æ˜¯â€œsafety Helmetâ€ä¹Ÿå¯ä»¥æ˜¯â€œsafety hatâ€ï¼Œâ€œhard hatâ€ç­‰ç­‰ã€‚

2.æ•°æ®æ¸…æ´—

æ˜¾ç„¶ç”¨ä»¥ä¸Šçˆ¬å–å¾—åˆ°çš„å›¾ç‰‡åŒ…å«å¤§é‡é‡å¤çš„ï¼Œæˆ–è€…æ˜¯å¹¶ä¸åŒ…å«ROIçš„å›¾ç‰‡ï¼Œéœ€è¦è¿‡æ»¤æ‰å¤§é‡çš„è¿™äº›å›¾ç‰‡ï¼Œè¿™é‡Œä»‹ç»è‡ªå·±ç”¨åˆ°çš„å‡ ä¸ªæ–¹æ³•ï¼š

(1)ç”¨å·²æœ‰çš„è¡Œäººæ£€æµ‹æ–¹æ³•è¿‡æ»¤æ‰å¤§éƒ¨åˆ†éROIå›¾åƒï¼›

(2)å¯ä»¥ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹zooï¼Œæ¯”å¦‚ImageNetåˆ†ç±»é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æå–ç‰¹å¾ï¼Œåˆ¤æ–­å›¾åƒç›¸ä¼¼åº¦ï¼Œå»é™¤æä¸ºç›¸ä¼¼çš„å›¾åƒï¼›

(3)å‰©ä½™çš„éƒ¨åˆ†å­˜åœ¨é‡åæˆ–è€…æ–‡ä»¶å¤§å°ä¸€è‡´çš„å›¾åƒï¼Œé€šå¸¸æƒ…å†µä¸‹è¿™äº›éƒ½æ˜¯ä¸åŒé“¾æ¥ä¸‹çš„ç›¸åŒå›¾ç‰‡ï¼Œåœ¨æ•°é‡å°‘çš„æƒ…å†µä¸‹å¯ä»¥æ‰‹åŠ¨æ¸…æ´—ã€‚

3.bounding boxæ ‡æ³¨

ç”¨çš„å¼€æºæ ‡æ³¨å·¥å…·labelImgï¼Œè¿™ä¸ªæ²¡ä»€ä¹ˆå¤šè¯´çš„ï¼Œæ˜¯ä¸ªä½“åŠ›æ´»ï¼Œä¸è¿‡ä¸€ä¸ªæ›´ä¸ºçœåŠ›çš„æ–¹æ³•æ˜¯**æ•°æ®å›çŒ**ï¼Œä¹Ÿå°±æ˜¯å…ˆç”¨æ ‡æ³¨å¥½çš„ä¸€éƒ¨åˆ†æ•°æ®è®­ç»ƒå‡ºä¸€ä¸ªç²—ç³™çš„æ£€æµ‹æ¨¡å‹ï¼Œç²¾åº¦è™½ç„¶ä¸é«˜ï¼Œä¸è¿‡å¯ä»¥æ‹¿æ¥å®šä½å‡ºå¤§è‡´çš„ç›®æ ‡åŒºåŸŸä½ç½®ï¼Œç„¶åè¿›è¡Œæ‰‹åŠ¨è°ƒæ•´bounding boxä½ç½®ï¼Œè¿™æ ·çœæ—¶çœåŠ›ï¼Œåå¤è¿™æ ·å¯ä»¥å‡å°‘å·¥æœŸã€‚å¦å¤–æ ‡æ³¨çš„è¿‡ç¨‹ä¸­ä¼šå‡ºä¸å°‘é—®é¢˜æ¯”å¦‚ç”±äºæ‰‹æŠ–å‡ºç°å›¾ä¸­å°åœˆçš„æƒ…å½¢,è¿™ç§æƒ…å†µä¼šå¯¼è‡´æ ‡æ³¨çš„xmlå‡ºç°bounding boxçš„å››ä¸ªåæ ‡å®½æˆ–é«˜ç›¸ç­‰ï¼Œæ˜¾ç„¶ä¸ç¬¦åˆå¸¸ç†ï¼Œæ‰€ä»¥éœ€è¦æ‰‹åŠ¨å†™è„šæœ¬æ£€æŸ¥å’Œå¤„ç†æœ‰è¿™ç§æˆ–è€…å…¶ä»–é—®é¢˜çš„xmlçš„annotationï¼Œæ¯”å¦‚è¿˜æœ‰çš„æ£€æµ‹ç®—æ³•ä¸éœ€è¦ä»€ä¹ˆéƒ½æ²¡æ ‡æ³¨çš„èƒŒæ™¯å›¾åƒï¼Œå¯ä»¥æ£€æµ‹æœ‰æ²¡æœ‰è¿™ç§â€œç©ºâ€ç±»åˆ«çš„æ•°æ®ï¼›ç”šè‡³æ˜¯ç¬”è¯¯æ•²é”™äº†ç±»åˆ«çš„æ ‡ç­¾ï¼›ç­‰ç­‰è¿™äº›éƒ½éœ€è¦æ‰‹åŠ¨å†™è‡ªåŠ¨åŒ–æˆ–åŠè‡ªåŠ¨åŒ–çš„è„šæœ¬æ¥åšçº é”™å¤„ç†ï¼Œè¿™æ ·çš„å·¥å…·åœ¨æ ‡æ³¨æ—¶åº”è¯¥ç»å¸¸ç”¨åˆ°ã€‚ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œä¸€æ—¦æ ‡æ³¨é¡¹ç›®å½¢æˆè§„æ¨¡ï¼Œè§„èŒƒçš„è‡ªåŠ¨åŒ–æµç¨‹ä¼šèŠ‚çœå¾ˆå¤šèµ„æºã€‚


### 2.âœ¨ æ¨¡å‹ä»‹ç»

æˆ‘ä»¬ä½¿ç”¨çº¯Tensorflowå®ç°çš„[YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf). åŒ…å«äº†è®­ç»ƒå’Œæµ‹è¯•è‡ªå·±æ•°æ®é›†çš„å…¨pipeline. å…¶ä¸»è¦çš„ç‰¹ç‚¹åŒ…æ‹¬:

- é«˜æ•ˆçš„ tf.data pipeline
- å°†COCOæ•°æ®é›†é¢„è®­ç»ƒçš„æ¨¡å‹è¿ç§»å­¦ä¹ 
- æ”¯æŒGPUç‰ˆçš„NMS.
- è®­ç»ƒå’Œæµ‹è¯•æ¨æ–­è¿‡ç¨‹å…¨éƒ¨æœ‰ä»£ç æ ·ä¾‹.
- ä½¿ç”¨Kmeansè‡ªå·±è®­ç»ƒå…ˆéªŒçš„anchor.


Python ç‰ˆæœ¬: 2 or 3

Packages:

- tensorflow >= 1.8.0 (æ”¯æŒtf.dataçš„ç‰ˆæœ¬éƒ½å¯ä»¥)
- opencv-python
- tqdm

å°†é¢„è®­ç»ƒçš„darknetçš„æƒé‡ä¸‹è½½ï¼Œä¸‹è½½åœ°å€ï¼š<https://pjreddie.com/media/files/yolov3.weights>,å¹¶å°†è¯¥weightæ–‡ä»¶æ‹·è´å¤§`./data/darknet_weights/`ä¸‹ï¼Œå› ä¸ºè¿™æ˜¯darknetç‰ˆæœ¬çš„é¢„è®­ç»ƒæƒé‡ï¼Œéœ€è¦è½¬åŒ–ä¸ºTensorflowå¯ç”¨çš„ç‰ˆæœ¬ï¼Œè¿è¡Œå¦‚ä¸‹ä»£ç å¯ä»¥å®ç°ï¼š

```shell
python convert_weight.py
```

è¿™æ ·è½¬åŒ–åçš„Tensorflow checkpointæ–‡ä»¶è¢«å­˜æ”¾åœ¨ï¼š`./data/darknet_weights/`ç›®å½•ã€‚ä½ ä¹Ÿå¯ä»¥ä¸‹è½½å·²ç»è½¬åŒ–å¥½çš„æ¨¡å‹ï¼š

[Googleäº‘ç›˜]((https://drive.google.com/drive/folders/1mXbNgNxyXPi7JNsnBaxEv1-nWr7SVoQt?usp=sharing) [GitHub Release](https://github.com/wizyoung/YOLOv3_TensorFlow/releases/) 


### 3.ğŸ”° è®­ç»ƒæ•°æ®æ„å»º

(1) annotationæ–‡ä»¶

è¿è¡Œ

```shell
python data_pro.py
```
åˆ†å‰²è®­ç»ƒé›†ï¼ŒéªŒè¯é›†ï¼Œæµ‹è¯•é›†å¹¶åœ¨`./data/my_data/`ä¸‹ç”Ÿæˆ`train.txt/val.txt/test.txt`ï¼Œå¯¹äºä¸€å¼ å›¾åƒå¯¹åº”ä¸€è¡Œæ•°æ®ï¼ŒåŒ…æ‹¬`image_index`,`image_absolute_path`,`box_1`,`box_2`,...,`box_n`,æ¯ä¸ªå­—æ®µä¸­é—´æ˜¯ç”¨ç©ºæ ¼åˆ†éš”çš„ï¼Œå…¶ä¸­:

+ `image_index`æ–‡æœ¬çš„è¡Œå·
+ `box_x`çš„å½¢å¼ä¸ºï¼š`label_index, x_min,y_min,x_max,y_max`(æ³¨æ„åæ ‡åŸç‚¹åœ¨å›¾åƒçš„å·¦ä¸Šè§’)
+ `label_index`æ˜¯labelå¯¹åº”çš„index(å–å€¼ä¸º0-class_num-1),è¿™é‡Œè¦æ³¨æ„YOLOç³»åˆ—çš„æ¨¡å‹è®­ç»ƒä¸SSDä¸åŒï¼Œlabelä¸åŒ…å«background

ä¾‹å­ï¼š

```
0 xxx/xxx/a.jpg 0 453 369 473 391 1 588 245 608 268
1 xxx/xxx/b.jpg 1 466 403 485 422 2 793 300 809 320
...
```

(2) class_namesæ–‡ä»¶:

`coco.names`æ–‡ä»¶åœ¨ `./data/` è·¯å¾„ä¸‹ï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªlabel name,ä¾‹å¦‚ï¼š

```
hat
person
```

(3) å…ˆéªŒanchoræ–‡ä»¶:

ä½¿ç”¨Kmeansç”Ÿæˆå…ˆéªŒanchors:

```
python get_kmeans.py
```

å¯ä»¥å¾—åˆ°9ä¸ªanchorså’Œå¹³å‡çš„IOU,æŠŠanchorsä¿å­˜åœ¨æ–‡æœ¬æ–‡ä»¶ï¼š`./data/yolo_anchors.txt`, 

**æ³¨æ„: Kmeansè®¡ç®—å‡ºçš„YOLO Anchorsæ˜¯åœ¨åœ¨è°ƒæ•´å¤§å°çš„å›¾åƒæ¯”ä¾‹çš„ï¼Œé»˜è®¤çš„è°ƒæ•´å¤§å°æ–¹æ³•æ˜¯ä¿æŒå›¾åƒçš„çºµæ¨ªæ¯”ã€‚**



### 4.ğŸ“ è®­ç»ƒ

ä¿®æ”¹`arg.py`ä¸­çš„ä¸€äº›å‚æ•°ï¼Œå¦‚ä¸‹ï¼š

<details>
<summary><mark><font color=darkred>ä¿®æ”¹arg.py</font></mark></summary>
<pre><code>
### Some paths
train_file = './data/my_data/train.txt'  # The path of the training txt file.
val_file = './data/my_data/val.txt'  # The path of the validation txt file.
restore_path = './data/darknet_weights/yolov3.ckpt'  # The path of the weights to restore.
save_dir = './checkpoint/'  # The directory of the weights to save.
log_dir = './data/logs/'  # The directory to store the tensorboard log files.
progress_log_path = './data/progress.log'  # The path to record the training progress.
anchor_path = './data/yolo_anchors.txt'  # The path of the anchor txt file.
class_name_path = './data/coco.names'  # The path of the class names.
### Training releated numbers
batch_size = 2  # éœ€è¦è°ƒæ•´ä¸ºè‡ªå·±çš„ç±»åˆ«æ•°
img_size = [416, 416]  # Images will be resized to `img_size` and fed to the network, size format: [width, height]
total_epoches = 500  # è®­ç»ƒå‘¨æœŸè°ƒæ•´
train_evaluation_step = 50  # Evaluate on the training batch after some steps.
val_evaluation_epoch = 1  # Evaluate on the whole validation dataset after some steps. Set to None to evaluate every epoch.
save_epoch = 10  # Save the model after some epochs.
batch_norm_decay = 0.99  # decay in bn ops
weight_decay = 5e-4  # l2 weight decay
global_step = 0  # used when resuming training
### tf.data parameters
num_threads = 10  # Number of threads for image processing used in tf.data pipeline.
prefetech_buffer = 5  # Prefetech_buffer used in tf.data pipeline.
### Learning rate and optimizer
optimizer_name = 'adam'  # Chosen from [sgd, momentum, adam, rmsprop]
save_optimizer = True  # Whether to save the optimizer parameters into the checkpoint file.
learning_rate_init = 1e-3
lr_type = 'exponential'  # Chosen from [fixed, exponential, cosine_decay, cosine_decay_restart, piecewise]
lr_decay_epoch = 5  # Epochs after which learning rate decays. Int or float. Used when chosen `exponential` and `cosine_decay_restart` lr_type.
lr_decay_factor = 0.96  # The learning rate decay factor. Used when chosen `exponential` lr_type.
lr_lower_bound = 1e-6  # The minimum learning rate.
# piecewise params
pw_boundaries = [60, 80]  # epoch based boundaries
pw_values = [learning_rate_init, 3e-5, 1e-4]
### Load and finetune
# Choose the parts you want to restore the weights. List form.
# Set to None to restore the whole model.
restore_part = ['yolov3/darknet53_body']
# Choose the parts you want to finetune. List form.
# Set to None to train the whole model.
update_part = ['yolov3/yolov3_head']
### other training strategies
multi_scale_train = False  # Whether to apply multi-scale training strategy. Image size varies from [320, 320] to [640, 640] by default.
use_label_smooth = False # Whether to use class label smoothing strategy.
use_focal_loss = False  # Whether to apply focal loss on the conf loss.
use_mix_up = False  # Whether to use mix up data augmentation strategy. # æ•°æ®å¢å¼º
use_warm_up = True  # whether to use warm up strategy to prevent from gradient exploding.
warm_up_epoch = 3  # Warm up training epoches. Set to a larger value if gradient explodes.
### some constants in validation
# nms éæå¤§å€¼æŠ‘åˆ¶
nms_threshold = 0.5  # iou threshold in nms operation
score_threshold = 0.5  # threshold of the probability of the classes in nms operation
nms_topk = 50  # keep at most nms_topk outputs after nms
# mAP eval
eval_threshold = 0.5  # the iou threshold applied in mAP evaluation
### parse some params
anchors = parse_anchors(anchor_path)
classes = read_class_names(class_name_path)
class_num = len(classes)
train_img_cnt = len(open(train_file, 'r').readlines())
val_img_cnt = len(open(val_file, 'r').readlines())
train_batch_num = int(math.ceil(float(train_img_cnt) / batch_size))  # iteration

lr_decay_freq = int(train_batch_num * lr_decay_epoch)
pw_boundaries = [float(i) * train_batch_num + global_step for i in pw_boundaries]
</code></pre>
</details>

è¿è¡Œï¼š


```shell
CUDA_VISIBLE_DEVICES=GPU_ID python train.py
```

æˆ‘ä»¬è®­ç»ƒçš„ç¯å¢ƒä¸ºï¼š

+ ubuntu 16.04
+ Tesla V100 32G



### 5.ğŸ”– æ¨æ–­

æˆ‘ä»¬ä½¿ç”¨`test_single_image.py`å’Œ`video_test.py`æ¨æ–­å•å¼ å›¾ç‰‡å’Œè§†é¢‘ï¼Œæµ‹è¯•Demoåœ¨Section 6æä¾›ã€‚ä½ å¯ä»¥ä¸‹è½½æˆ‘ä»¬é¢„è®­ç»ƒçš„å®‰å…¨å¸½è¯†åˆ«æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œä¸‹è½½åœ°å€ï¼š<>


### 6.â›Demo

![]()

![]()

![]()


### 7.â›è®­ç»ƒçš„ä¸€äº›Trick

è¿™äº›Trickæ¥æºäºï¼š<https://github.com/wizyoung/YOLOv3_TensorFlow>

(1) ä½¿ç”¨two-stageè®­ç»ƒæˆ–one-stageè®­ç»ƒ:

Two-stage training:

First stage: Restore darknet53_body part weights from COCO checkpoints, train the yolov3_head with big learning rate like 1e-3 until the loss reaches to a low level.

Second stage: Restore the weights from the first stage, then train the whole model with small learning rate like 1e-4 or smaller. At this stage remember to restore the optimizer parameters if you use optimizers like adam.

One-stage training:

Just restore the whole weight file except the last three convolution layers (Conv_6, Conv_14, Conv_22). In this condition, be careful about the possible nan loss value.

(2) args.pyä¸­æœ‰å¾ˆå¤šæœ‰ç”¨çš„è®­ç»ƒå‚æ•°è°ƒæ•´ç­–ç•¥:

Cosine decay of lr (SGDR)

Multi-scale training

Label smoothing

Mix up data augmentation

Focal loss

è¿™ä¹ˆå¤šç­–ç•¥ï¼Œä¸ä¸€å®šéƒ½èƒ½æå‡ä½ çš„æ¨¡å‹æ€§èƒ½ï¼Œæ ¹æ®è‡ªå·±çš„æ•°æ®é›†è‡ªè¡Œè°ƒæ•´é€‰æ‹©.

(3) æ³¨æ„ï¼š

This [paper](https://arxiv.org/abs/1902.04103) from gluon-cv has proved that data augmentation is critical to YOLO v3, which is completely in consistent with my own experiments. Some data augmentation strategies that seems reasonable may lead to poor performance. For example, after introducing random color jittering, the mAP on my own dataset drops heavily. Thus I hope you pay extra attention to the data augmentation.

(4) Loss nan? Setting a bigger warm_up_epoch number or smaller learning rate and try several more times. If you fine-tune the whole model, using adam may cause nan value sometimes. You can try choosing momentum optimizer.


### 8.ğŸ˜‰ è‡´è°¢

Name                      |   GitHub                                                       |
:-:                       |  :-:                                                           |
:shipit: **Wizyoung**     |   <https://github.com/wizyoung/YOLOv3_TensorFlow>              |
:shipit: **njvisionpower**     |<https://github.com/njvisionpower/Safety-Helmet-Wearing-Dataset>|
:shipit: **HCIILAB**     | <https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release>         |




